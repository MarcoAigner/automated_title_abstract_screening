{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Preprocessing\n",
    "This notebook encompasses general preprocessing steps to prepare the texts for classification in all scenarios. \n",
    "\n",
    "These are:\n",
    "- Removing HTML\n",
    "- Translating non-English texts\n",
    "- Filtering texts above or below a common word count\n",
    "- Removing duplicate entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Preparation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data\n",
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the data is stored\n",
    "directory = '../../../../data/datasets/03_pubmed'\n",
    "\n",
    "# Output directory\n",
    "output_directory = '../../../../data/datasets/04_preprocessed'\n",
    "\n",
    "# Load the data\n",
    "datasets = data.dict_from_directory(directory, type='polars')\n",
    "\n",
    "# individual datasets\n",
    "adhd = datasets['adhd']\n",
    "animal_depression = datasets['animal_depression']\n",
    "atypical_antipsychotics = datasets['atypical_antipsychotics']\n",
    "calcium_channel_blockers = datasets['calcium_channel_blockers']\n",
    "oral_hypoglycemics = datasets['oral_hypoglycemics']\n",
    "pancreatic_surgery = datasets['pancreatic_surgery']\n",
    "\n",
    "# combine all datasets\n",
    "all_datasets = pl.DataFrame(\n",
    ")\n",
    "\n",
    "for subject, dataset in datasets.items():\n",
    "    all_datasets = all_datasets.vstack(dataset.with_columns(pl.lit(subject).alias('dataset')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removal of Abstracts and Articles\n",
    "Remove non-English abstracts and abstracts with more than 489 words.\n",
    "\n",
    "Afterwards, remove articles without an abstract, as those do not contain sufficient information to decide on inclusion or exclusion in title/abstract-screening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_duplicates = {\n",
    "    'animal_depression': ['doi', 'openalex_id', 'pubmed_id'],\n",
    "    'pancreatic_surgery': ['doi', 'pubmed_id', 'webofscience_id']\n",
    "}\n",
    "\n",
    "for subject, dataset in datasets.items():\n",
    "    if subject in known_duplicates.keys():\n",
    "        for column in known_duplicates[subject]:\n",
    "\n",
    "            # save nulls as they are lost to .unique()\n",
    "            null = datasets[subject].filter(\n",
    "                pl.col(column).is_null()\n",
    "            )\n",
    "\n",
    "            # drop duplicate values - also drops null values\n",
    "            unique = datasets[subject].filter(\n",
    "                pl.col(column).is_unique()\n",
    "            )\n",
    "\n",
    "            # combine the unique and null values\n",
    "            filtered = unique.vstack(null)\n",
    "\n",
    "            # override the dataset with the filtered dataset\n",
    "            datasets[subject] = filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-English Abstracts\n",
    "Hard-code the manually determined indices of the English and non-English abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actually_english = {\n",
    "    'adhd': [521],\n",
    "    'animal_depression': [16, 743, 1528],\n",
    "    'pancreatic_surgery': [15500, 24419, 24904, 24951, 29967]\n",
    "}\n",
    "\n",
    "not_english = {\n",
    "    'adhd': [667,759,785,801],\n",
    "    'animal_depression': [266, 421, 675, 848, 968, 1162, 1250, 1521, 1644, 1919, 1947],\n",
    "    'pancreatic_surgery': [200, 17096, 17944]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the language code for the actual English abstracts with 'en'. Then, remove the abstracts of articles with a language code other than 'en'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dataset in datasets.items():\n",
    "    if subject in actually_english.keys():\n",
    "        dataset =  dataset.with_columns(\n",
    "            pl.when(\n",
    "                pl.col('index').is_in(actually_english[subject]),\n",
    "            ).then(\n",
    "                pl.lit('en')\n",
    "            ).otherwise(\n",
    "                pl.col('language_abstract')).alias('language_abstract'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset = dataset.with_columns(\n",
    "            pl.when(\n",
    "                pl.col('index').is_in(not_english[subject]),\n",
    "            ).then(pl.lit(None))\n",
    "            .otherwise(pl.col('abstract'))\n",
    "            .alias('abstract')\n",
    "        )\n",
    "\n",
    "        datasets[subject] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that non-English abstracts were indeed removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (18, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>abstract</th><th>language_abstract</th></tr><tr><td>u32</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>667</td><td>null</td><td>&quot;ceb&quot;</td></tr><tr><td>759</td><td>null</td><td>&quot;de&quot;</td></tr><tr><td>785</td><td>null</td><td>&quot;pt&quot;</td></tr><tr><td>801</td><td>null</td><td>&quot;de&quot;</td></tr><tr><td>266</td><td>null</td><td>&quot;de&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1919</td><td>null</td><td>&quot;de&quot;</td></tr><tr><td>1947</td><td>null</td><td>&quot;war&quot;</td></tr><tr><td>200</td><td>null</td><td>&quot;de&quot;</td></tr><tr><td>17096</td><td>null</td><td>&quot;es&quot;</td></tr><tr><td>17944</td><td>null</td><td>&quot;fr&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (18, 3)\n",
       "┌───────┬──────────┬───────────────────┐\n",
       "│ index ┆ abstract ┆ language_abstract │\n",
       "│ ---   ┆ ---      ┆ ---               │\n",
       "│ u32   ┆ str      ┆ str               │\n",
       "╞═══════╪══════════╪═══════════════════╡\n",
       "│ 667   ┆ null     ┆ ceb               │\n",
       "│ 759   ┆ null     ┆ de                │\n",
       "│ 785   ┆ null     ┆ pt                │\n",
       "│ 801   ┆ null     ┆ de                │\n",
       "│ 266   ┆ null     ┆ de                │\n",
       "│ …     ┆ …        ┆ …                 │\n",
       "│ 1919  ┆ null     ┆ de                │\n",
       "│ 1947  ┆ null     ┆ war               │\n",
       "│ 200   ┆ null     ┆ de                │\n",
       "│ 17096 ┆ null     ┆ es                │\n",
       "│ 17944 ┆ null     ┆ fr                │\n",
       "└───────┴──────────┴───────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['adhd'].vstack(\n",
    "    datasets['animal_depression']\n",
    ").vstack(\n",
    "    datasets['pancreatic_surgery']\n",
    ").filter(\n",
    "    pl.col('language_abstract') != 'en'\n",
    ").select(['index', 'abstract', 'language_abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Abstracts\n",
    "Remove abstracts that have more words than the limit of 489 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_LIMIT = 489\n",
    "\n",
    "for subject, dataset in datasets.items():\n",
    "\n",
    "    # list of indices of abstracts that are above the word limit\n",
    "    idx_long_abstracts = dataset.filter(\n",
    "        pl.col('abstract_word_count') > WORD_LIMIT\n",
    "    ).select('index').to_series().to_list()\n",
    "\n",
    "    # remove abstracts that are above the word limit\n",
    "    dataset = dataset.with_columns(\n",
    "            pl.when(\n",
    "                pl.col('index').is_in(idx_long_abstracts),\n",
    "            ).then(pl.lit(None))\n",
    "            .otherwise(pl.col('abstract'))\n",
    "            .alias('abstract')\n",
    "        )\n",
    "    \n",
    "    datasets[subject] = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Abstracts\n",
    "Remove articles without an abstract as they do not contain sufficient information to decide on inclusion or exclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to document, how many abstracts are removed\n",
    "documentation = pl.DataFrame(\n",
    "    {\n",
    "        'dataset': datasets.keys(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# lengths of the datasets before removing articles with empty abstracts\n",
    "lengths_before = [len(dataset) for dataset in datasets.values()]\n",
    "\n",
    "# add the initial lengths of the datasets\n",
    "documentation = documentation.with_columns(\n",
    "    pl.Series(\"length_before\", lengths_before)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove articles with empty abstracts\n",
    "for subject, dataset in datasets.items():\n",
    "    datasets[subject] = dataset.filter(\n",
    "        pl.col('abstract').is_not_null()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate, how many articles were removed due to missing abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dataset</th><th>length_before</th><th>length_after</th><th>abstracts_removed</th><th>percentage_removed</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;adhd&quot;</td><td>851</td><td>798</td><td>53</td><td>0.06228</td></tr><tr><td>&quot;atypical_antipsychotics&quot;</td><td>1120</td><td>1049</td><td>71</td><td>0.063393</td></tr><tr><td>&quot;calcium_channel_blockers&quot;</td><td>1218</td><td>1129</td><td>89</td><td>0.073071</td></tr><tr><td>&quot;oral_hypoglycemics&quot;</td><td>503</td><td>458</td><td>45</td><td>0.089463</td></tr><tr><td>&quot;pancreatic_surgery&quot;</td><td>34180</td><td>30252</td><td>3928</td><td>0.114921</td></tr><tr><td>&quot;animal_depression&quot;</td><td>1989</td><td>1691</td><td>298</td><td>0.149824</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 5)\n",
       "┌──────────────────────────┬───────────────┬──────────────┬───────────────────┬────────────────────┐\n",
       "│ dataset                  ┆ length_before ┆ length_after ┆ abstracts_removed ┆ percentage_removed │\n",
       "│ ---                      ┆ ---           ┆ ---          ┆ ---               ┆ ---                │\n",
       "│ str                      ┆ i64           ┆ i64          ┆ i64               ┆ f64                │\n",
       "╞══════════════════════════╪═══════════════╪══════════════╪═══════════════════╪════════════════════╡\n",
       "│ adhd                     ┆ 851           ┆ 798          ┆ 53                ┆ 0.06228            │\n",
       "│ atypical_antipsychotics  ┆ 1120          ┆ 1049         ┆ 71                ┆ 0.063393           │\n",
       "│ calcium_channel_blockers ┆ 1218          ┆ 1129         ┆ 89                ┆ 0.073071           │\n",
       "│ oral_hypoglycemics       ┆ 503           ┆ 458          ┆ 45                ┆ 0.089463           │\n",
       "│ pancreatic_surgery       ┆ 34180         ┆ 30252        ┆ 3928              ┆ 0.114921           │\n",
       "│ animal_depression        ┆ 1989          ┆ 1691         ┆ 298               ┆ 0.149824           │\n",
       "└──────────────────────────┴───────────────┴──────────────┴───────────────────┴────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lengths of the datasets after removing articles with empty abstracts\n",
    "lengths_after = [len(dataset) for dataset in datasets.values()]\n",
    "\n",
    "# how many articles were removed, absolutely and relative to the total\n",
    "documentation.with_columns(\n",
    "    pl.Series(\"length_after\", lengths_after)\n",
    ").with_columns(\n",
    "    (\n",
    "        pl.col('length_before') - pl.col('length_after')\n",
    "    ).alias('abstracts_removed')\n",
    ").with_columns(\n",
    "    (\n",
    "        pl.col('abstracts_removed') / pl.col('length_before')\n",
    "    ).alias('percentage_removed')\n",
    ").sort(by='percentage_removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Removal\n",
    "### HTML\n",
    "HTML tags cause noise within the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = datasets['adhd'].to_pandas().iloc[[456, 565]].abstract.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to automatically remove HTML from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html(text: str)-> str:\n",
    "    \"\"\"Remove html tags from a string\n",
    "    \n",
    "    Args:\n",
    "    text: str: a string containing html tags\n",
    "\n",
    "    Returns:\n",
    "    str: a string without html tags\n",
    "    \"\"\"\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove HTML from all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import warnings\n",
    "\n",
    "# BeautifulSoup thinks some titles to be similar to filenames \n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "for subject, dataset in datasets.items():\n",
    "    datasets[subject] = dataset.with_columns([\n",
    "        pl.col('title').map_elements(remove_html, return_dtype=pl.String),\n",
    "        pl.col('abstract').map_elements(remove_html, return_dtype=pl.String)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that HTML was indeed removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With HTML:\n",
      "\n",
      "Patients with myotonic dystrophy frequently suffer from excess daytime sleepiness, which can be a si\n",
      "In a randomized, double-blind study in children undergoing elective orthopaedic surgery, we have ass\n",
      "\n",
      "\n",
      "Without HTML:\n",
      "\n",
      "Patients with myotonic dystrophy frequently suffer from excess daytime sleepiness, which can be a si\n",
      "In a randomized, double-blind study in children undergoing elective orthopaedic surgery, we have ass\n"
     ]
    }
   ],
   "source": [
    "after = datasets['adhd'].to_pandas().iloc[[456, 565]].abstract.values\n",
    "\n",
    "print('With HTML:', end='\\n\\n')\n",
    "[print(abstract[:100], end='\\n') for abstract in before];\n",
    "print('\\n\\nWithout HTML:', end='\\n\\n')\n",
    "[print(abstract[:100], end='\\n') for abstract in after];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characters Only\n",
    "Remove all digits and special characters by regular expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text: str) -> str:\n",
    "    \"\"\"Remove special characters from a string\n",
    "    \n",
    "    Args:\n",
    "    text: str: a string containing special characters\n",
    "\n",
    "    Returns:\n",
    "    str: a string without special characters\n",
    "    \"\"\"\n",
    "    # remove newlines and carriage returns\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "    \n",
    "    # matches characters only\n",
    "    pattern = r'[^a-zA-Z\\s]+'\n",
    "\n",
    "    # apply the pattern to clean the string\n",
    "    clean_string = re.sub(pattern, '', text)\n",
    "\n",
    "    # ensure that there are no multiple spaces\n",
    "    clean_string = ' '.join(clean_string.split())\n",
    "\n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate that the function works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is A tst nd t wrks'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'This,  i2s A  t3st!\\n\\r4nd  1t  w0rks.'\n",
    "remove_special_characters(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to all titles and abstracts to keep characters only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dataset in datasets.items():\n",
    "    datasets[subject] = dataset.with_columns([\n",
    "        pl.col('title').map_elements(\n",
    "            remove_special_characters,\n",
    "            return_dtype=pl.String\n",
    "        ),\n",
    "        pl.col('abstract').map_elements(\n",
    "            remove_special_characters,\n",
    "            return_dtype=pl.String\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export\n",
    "Export the preprocessed data for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dataset in datasets.items():\n",
    "    dataset.write_csv(f'{output_directory}/{subject}_preprocessed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated_screening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
