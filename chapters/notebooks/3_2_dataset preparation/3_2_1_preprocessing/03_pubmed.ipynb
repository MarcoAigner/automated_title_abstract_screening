{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from metapub import PubMedFetcher\n",
    "from tqdm.notebook import tqdm\n",
    "from src import data\n",
    "import polars as pl\n",
    "\n",
    "#TODO: move to .env file\n",
    "os.environ['NCBI_API_KEY'] = '9b3142c8c09a8527c8d9bc616f5ff2813d08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\automated_title_abstract_screening', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\python312.zip', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\DLLs', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\Lib', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening', '', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\mfaig\\\\miniforge3\\\\envs\\\\automated_screening\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: '../../../../data/03_openalex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_directory_openalex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../../data/03_openalex\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m pl_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_directory_openalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpolars\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\automated_title_abstract_screening\\src\\data.py:21\u001b[0m, in \u001b[0;36mdict_from_directory\u001b[1;34m(directory, separator, type)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mReturn a dictionary containing dataframes from all .csv-files in a directory.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    dict: Dictionary with subjects as keys and dataframes as values.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# all .csv-files in the directory\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# expects files to end with '_[annotation].csv'\u001b[39;00m\n\u001b[0;32m     24\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(.*)_.*$\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: '../../../../data/03_openalex'"
     ]
    }
   ],
   "source": [
    "data_directory_openalex = '../../../../data/03_openalex'\n",
    "pl_datasets = data.dict_from_directory(data_directory_openalex, separator=',', type='polars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Literature IDs\n",
    "## SYNERGY\n",
    "SYNERGY only has pubmed_ids, rename accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dataset in pl_datasets.items():\n",
    "    if subject != 'pancreatic_surgery':\n",
    "        pl_datasets[subject] = dataset.rename({'literature_id': 'pubmed_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVIglance\n",
    "The EVIglance dataset contains ids from pubmed, cochrane central, web of science and others. \n",
    "Detect the type of the first three ids and assign them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_datasets['pancreatic_surgery'] = pl_datasets['pancreatic_surgery'].with_columns(\n",
    "    pl.when(pl.col('literature_id').str.starts_with('CN-'))\n",
    "    .then(pl.col('literature_id').alias('central_id')),\n",
    "    pl.when(pl.col('literature_id').str.starts_with('WOS:'))\n",
    "    .then(pl.col('literature_id').alias('webofscience_id')),\n",
    "    pl.when(pl.col('literature_id').str.contains(\"^(\\\\d)*$\"))\n",
    "    .then(pl.col('literature_id').alias('pubmed_id')),\n",
    ").select(pl.all().exclude('literature_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Casting\n",
    "The PubMed ID is wrongfully formatted as Float64 in the animal depression dataset and as String in the pancreatic surgery dataset. \n",
    "Cast both to Integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_datasets['animal_depression'] = pl_datasets['animal_depression'].cast({pl.Float64: pl.Int64})\n",
    "pl_datasets['pancreatic_surgery'] = pl_datasets['pancreatic_surgery'].cast({'pubmed_id': pl.Int64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "Define a uniform schema that all datasets will use from now on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pl.Schema({\n",
    "    \"include\": pl.Boolean,\n",
    "    \"title\": pl.String,\n",
    "    \"abstract\": pl.String,\n",
    "    \"first_author\": pl.String,\n",
    "    \"year\": pl.Int16,\n",
    "    \"journal\": pl.String,\n",
    "    \"doi\": pl.String,\n",
    "    \"pubmed_id\": pl.Int64,\n",
    "    \"authors\": pl.String,\n",
    "    \"pubmed_type\": pl.String,\n",
    "    \"publication_types\": pl.String,\n",
    "    \"mesh\": pl.String,\n",
    "    \"webofscience_id\": pl.String,\n",
    "    \"central_id\": pl.String,\n",
    "    \"openalex_id\": pl.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject, dataset in pl_datasets.items():\n",
    "    df = pl.DataFrame(schema=schema)\n",
    "    pl_datasets[subject] = pl.concat(items=[pl.DataFrame(schema=schema), dataset], how='diagonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "Export the data in this format if the target folder is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_schema = '../../../../data/031_schema'\n",
    "\n",
    "# save the data in the provided schema \n",
    "\n",
    "[dataset.write_csv(f'{data_directory_schema}/{subject}_schema.csv') for subject, dataset in pl_datasets.items()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_from_pubmed(dataframe: pd.DataFrame, subject: str) -> pd.DataFrame:\n",
    "\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    for INDEX, row in tqdm(df.iterrows(), total=df.shape[0], desc=subject, leave=True):\n",
    "\n",
    "        if not pd.isnull(row['pubmed_id']):\n",
    "            try:\n",
    "                metadata = PubMedFetcher().article_by_pmid(row['pubmed_id'])\n",
    "\n",
    "                # fill columns if they are missing\n",
    "                df.at[INDEX, 'title'] = metadata.title if pd.isnull(row['title']) else row['title']\n",
    "                df.at[INDEX, 'abstract'] = metadata.abstract if pd.isnull(row['abstract']) else row['abstract']\n",
    "                df.at[INDEX, 'first_author'] = metadata.author1_last_fm if pd.isnull(row['first_author']) else row['first_author']\n",
    "                df.at[INDEX, 'year'] = metadata.year if pd.isnull(row['year']) else row['year']\n",
    "                df.at[INDEX, 'journal'] = metadata.journal if pd.isnull(row['journal']) else row['journal']\n",
    "                df.at[INDEX, 'doi'] = metadata.doi if pd.isnull(row['doi']) else row['doi']\n",
    "                df.at[INDEX, 'pubmed_id'] = metadata.pmid if pd.isnull(row['pubmed_id']) else row['pubmed_id']\n",
    "                df.at[INDEX, 'authors'] = metadata.authors_str if pd.isnull(row['authors']) else row['authors']\n",
    "                df.at[INDEX, 'pubmed_type'] = metadata.pubmed_type if pd.isnull(row['pubmed_type']) else row['pubmed_type']\n",
    "                df.at[INDEX, 'publication_types'] = '; '.join([f'{key}: {value}' for key, value in metadata.publication_types.items()]) if pd.isnull(row['publication_types']) else row['publication_types']\n",
    "                df.at[INDEX, 'mesh'] = '; '.join([f'{key}: {value['descriptor_name']}' for key, value in metadata.mesh.items()]) if pd.isnull(row['mesh']) else row['mesh']\n",
    "                df.at[INDEX, 'webofscience_id'] = row['webofscience_id']\n",
    "                df.at[INDEX, 'central_id'] = row['central_id']\n",
    "                df.at[INDEX, 'openalex_id'] = row['openalex_id']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_datasets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory_uniform = '../../../../data/03_pubmed'\n",
    "\n",
    "for subject, dataset in pl_datasets.items():\n",
    "    # download metadata from pubmed eutils\n",
    "    downloaded_df = fill_missing_from_pubmed(dataset.to_pandas(), subject)\n",
    "\n",
    "    # transform the dataframe to polars\n",
    "    polars_df = pl.DataFrame(data=downloaded_df, schema=schema)\n",
    "    \n",
    "    # add to the dictionary to access later\n",
    "    downloaded_datasets[subject] = polars_df\n",
    "    \n",
    "    # save directly to csv \n",
    "    polars_df.write_csv(f'{data_directory_uniform}/{subject}_pubmed.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polars_df = pl.DataFrame(data=downloaded_df.astype({'pubmed_id': 'Int64'}), schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_df.to_csv(f'{data_directory_uniform}/{subject}_pubmed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated_screening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
