{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Supervised Machine Learning\n",
    "This notebook contains the code to classify the articles within each dataset using supervised machine learning models.\n",
    "## Preparation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import polars as pl\n",
    "from src import data\n",
    "\n",
    "# scikit-learn - machine learning library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# imbalanced-learn - library for dealing with imbalanced datasets\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# loading bars\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the data is stored\n",
    "data_directory = '../../../data/datasets/04_preprocessed'\n",
    "\n",
    "# load the data\n",
    "datasets = data.dict_from_directory(data_directory, type='polars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_sets(df):\n",
    "    \"\"\"\n",
    "    Return a train-test split of the data\n",
    "\n",
    "    Args:\n",
    "        df: Polars DataFrame with columns 'title', 'abstract', and 'include'.\n",
    "\n",
    "    Returns:\n",
    "        X_train: list of strings, training data.\n",
    "        X_test: list of strings, test data.\n",
    "        y_train: list of booleans, training labels.\n",
    "        y_test: list of booleans, test labels.\n",
    "    \"\"\"\n",
    "    # combine title and abstract into one column\n",
    "    # fill null values with empty strings to avoid errors\n",
    "    combined = df.select(\n",
    "        pl.col('index'),\n",
    "        pl.concat_str(\n",
    "            pl.col('title').fill_null(''),\n",
    "            pl.col('abstract').fill_null(''),\n",
    "            separator=' ',\n",
    "        ).alias('text')\n",
    "    )\n",
    "\n",
    "    # features\n",
    "    #X = combined.to_series().to_numpy()\n",
    "    X = combined.to_pandas()\n",
    "    X.set_index('index', inplace=True)\n",
    "\n",
    "    # target\n",
    "    #y = df['include'].to_numpy()\n",
    "    y = df['include'].to_pandas()\n",
    "    y = y.set_axis(X.index)\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, \n",
    "        y, \n",
    "        test_size=0.3, # the test set will be 30% of the data\n",
    "        random_state=42,  # important for reproducibility\n",
    "        stratify=y # important for imbalanced classes\n",
    "    ) \n",
    "\n",
    "    # get the indices of the test set\n",
    "    test_indices = X_test.index\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(estimator):\n",
    "    \"\"\"\n",
    "    Return a pipeline ready encapuslating a given estimator.\n",
    "    The pipeline includes Tf-idf vectorization and random undersampling.\n",
    "\n",
    "    Args:\n",
    "        estimator: scikit-learn estimator.\n",
    "    \n",
    "    Returns:\n",
    "        pipeline: imbalanced-learn pipeline.\n",
    "    \"\"\"\n",
    "    return Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('undersampling', RandomUnderSampler(\n",
    "            sampling_strategy='auto',\n",
    "            random_state=42\n",
    "            )\n",
    "        ),\n",
    "        ('estimator', estimator)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "### Defining Estimators\n",
    "Article classes will be predicted by the following four estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of estimators to predict with\n",
    "# class weights will be used for estimators which support it\n",
    "estimators = {\n",
    "    'logistic_regression': LogisticRegression(class_weight='balanced'),\n",
    "    'random_forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    'support_vector_machine': SVC(class_weight='balanced'),\n",
    "    'naive_bayes': ComplementNB(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Article Classes\n",
    "Predict classes for each dataset and estimator each. Save the predictions besides the true values of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcee3c88ead40ee921fdc932b10f3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7484567ce18c4b8d89df72f94832fa1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a79a675867d45f992cd24ce8c761532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cea3efa38415abcf151ad98442655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437f7c5832a540d4800453f74f1c790a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8637257f640d4a74a67a52d3fe3138c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5ecd9da9cd4dfca9c2b89ecd7cae8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Estimators:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dictionary to store predictions for each dataset and estimator\n",
    "predictions = {}\n",
    "\n",
    "# iterate over datasets\n",
    "for subject, dataset in tqdm(\n",
    "    iterable=datasets.items(),\n",
    "    desc='Datasets',\n",
    "    total=len(datasets),\n",
    "    leave=True\n",
    "):\n",
    "\n",
    "    # use the same train-test split for all estimators\n",
    "    X_train, X_test, y_train, y_test, test_indices = create_train_test_sets(\n",
    "        dataset\n",
    "    )\n",
    "\n",
    "    # dataframe to store true values and predictions per estimator\n",
    "    predictions[subject] = pl.DataFrame(\n",
    "        {\n",
    "            'index': test_indices,\n",
    "            'true': y_test\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    X_train = X_train['text'].to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    X_test = X_test['text'].to_numpy()\n",
    "\n",
    "    # iterate over estimators\n",
    "    for name, estimator in tqdm(\n",
    "        iterable=estimators.items(),\n",
    "        desc='Estimators',\n",
    "        total=len(estimators),\n",
    "        leave=False,\n",
    "    ):\n",
    "        \n",
    "        # create a prediction pipeline\n",
    "        pipeline = create_pipeline(estimator)\n",
    "\n",
    "        # fit the estimator\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # predict class labels\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # store the predictions\n",
    "        predictions[subject] = predictions[subject].with_columns(\n",
    "            pl.Series(name=name, values=y_pred)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to save the predictions\n",
    "export_path = '../../../data/predictions/supervised_machine_learning'\n",
    "\n",
    "for subject, df in predictions.items():\n",
    "    df.write_csv(f'{export_path}/{subject}_pred.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automated_screening",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
